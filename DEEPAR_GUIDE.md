# DeepAR Implementation - Complete Guide

## ‚úÖ **FULL IMPLEMENTATION WITH GPU SUPPORT**

This is a **production-ready** DeepAR implementation with:
- ‚úÖ GluonTS + PyTorch backend
- ‚úÖ GPU support (RTX 4050)
- ‚úÖ Multiple external features (revenue, price, promotions, etc.)
- ‚úÖ Flexible preprocessing
- ‚úÖ Probabilistic forecasting
- ‚úÖ Model versioning

---

## üéØ **What's Included**

### **4 Complete Modules:**

1. **`external_features.py`** - Multi-feature preprocessing
   - Lag features (1, 7, 14 days)
   - Rolling averages (7, 14, 30 days)
   - Normalization (standard/minmax/robust)
   - Missing value handling
   - Outlier clipping

2. **`data_formatting.py`** - GluonTS dataset creation
   - Pandas ‚Üí GluonTS ListDataset conversion
   - Dynamic real features support
   - Static categorical features support
   - Per-item dataset creation

3. **`model_training.py`** - Training with GPU
   - PyTorch backend
   - GPU/CPU auto-detection
   - Multi-feature support
   - Model versioning
   - Probabilistic training

4. **`prediction.py`** - Probabilistic forecasting
   - Monte Carlo sampling
   - Confidence intervals
   - Quantile predictions
   - External features in inference

---

## üöÄ **Quick Start**

### **Step 1: Install Dependencies**

```bash
# Install PyTorch with CUDA support (for RTX 4050)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install GluonTS with PyTorch backend
pip install -r requirements/deepar.txt
```

### **Step 2: Prepare Your Data**

Your CSV should have:
```csv
ds,product_id,sales_quantity,revenue,price
2024-01-01,PROD_001,100,1000,10.5
2024-01-02,PROD_001,110,1100,10.5
2024-01-03,PROD_001,105,1050,10.5
```

**Required columns:**
- `ds` - Date
- `sales_quantity` - Target variable
- `revenue` - External feature (or any other features you want)

**Optional columns:**
- `price`, `promotions`, `marketing_spend`, etc.

### **Step 3: Configure External Features**

Edit `config/deepar_config.yaml`:

```yaml
external_features:
  enabled: true
  features:
    # Enable the features you have
    - name: "revenue"
      type: "dynamic_real"
      enabled: true
    
    - name: "price"
      type: "dynamic_real"
      enabled: true  # Set to true if you have price data
    
    - name: "promotions"
      type: "dynamic_real"
      enabled: false  # Set to true if you have promotions data
```

### **Step 4: Train Model**

```bash
# Train with GPU (default)
python scripts/deepar/model_training.py --data data/processed/cleaned_data.csv

# Train with CPU (if no GPU)
python scripts/deepar/model_training.py --data data/processed/cleaned_data.csv --cpu
```

### **Step 5: Generate Predictions**

```bash
python scripts/deepar/prediction.py \
  --model models/deepar/deepar_v20241226_* \
  --data data/processed/cleaned_data.csv \
  --samples 100
```

---

## üñ•Ô∏è **GPU Configuration**

### **Automatic GPU Detection**

By default, DeepAR auto-detects your GPU:

```yaml
# config/deepar_config.yaml
device:
  use_gpu: true
  gpu_id: 0
  auto_detect: true  # Automatically use GPU if available
```

### **Force CPU Training**

```yaml
device:
  use_gpu: false
  auto_detect: false
```

Or use command line:
```bash
python scripts/deepar/model_training.py --data data.csv --cpu
```

### **Check GPU Status**

```python
import torch

print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU name: {torch.cuda.get_device_name(0)}")
print(f"CUDA version: {torch.version.cuda}")
```

---

## üé® **External Features Configuration**

### **Multiple Features Support**

You can use **any number** of external features:

```yaml
external_features:
  enabled: true
  features:
    # Dynamic features (change over time)
    - name: "revenue"
      type: "dynamic_real"
      enabled: true
    
    - name: "price"
      type: "dynamic_real"
      enabled: true
    
    - name: "promotions"
      type: "dynamic_real"
      enabled: true
    
    - name: "marketing_spend"
      type: "dynamic_real"
      enabled: false
    
    - name: "competitor_price"
      type: "dynamic_real"
      enabled: false
    
    # Static features (don't change)
    - name: "product_category"
      type: "static_cat"
      enabled: false
    
    - name: "region"
      type: "static_cat"
      enabled: false
```

### **Feature Preprocessing**

```yaml
preprocessing:
  # Create lag features
  lag_external: true
  lag_periods: [1, 7, 14]
  
  # Create rolling averages
  rolling_external: true
  rolling_windows: [7, 14, 30]
  
  # Normalization (recommended)
  normalize: true
  normalization_method: "standard"  # or "minmax", "robust"
  
  # Handle missing values
  fill_method: "forward"  # or "backward", "interpolate", "mean"
  
  # Clip outliers
  clip_outliers: true
  clip_std: 3
```

---

## üìä **Expected Performance**

### **With GPU (RTX 4050):**
- Training time: **5-15 minutes** (50 epochs)
- Prediction time: **< 1 minute**
- Expected MAPE: **8-12%**

### **With CPU:**
- Training time: **30-60 minutes** (50 epochs)
- Prediction time: **2-5 minutes**
- Expected MAPE: **8-12%** (same accuracy, just slower)

### **Performance Tips:**
1. **Use GPU** for faster training
2. **Reduce epochs** for quicker experiments (try 20-30)
3. **Reduce batch_size** if GPU memory issues (try 16)
4. **Increase hidden_size** for better accuracy (try 60-80)

---

## üîß **Hyperparameter Tuning**

### **Architecture:**
```yaml
deepar:
  num_layers: 2        # More layers = more complex patterns
  hidden_size: 40      # Larger = more capacity (try 60-80)
  dropout_rate: 0.1    # Prevent overfitting (0.1-0.3)
```

### **Training:**
```yaml
  epochs: 50           # More epochs = better fit (try 30-100)
  batch_size: 32       # Larger = faster but more memory
  learning_rate: 0.001 # Lower = more stable (try 0.0001-0.01)
```

### **Context:**
```yaml
  context_length: 90   # How much history to use (try 60-120)
  prediction_length: 30 # Forecast horizon
```

---

## üìà **Probabilistic Forecasting**

DeepAR provides **confidence intervals**:

```python
predictions = predictor.predict(df, num_samples=100)

# Columns:
# - forecast: Mean prediction
# - forecast_q10: 10th percentile (lower bound)
# - forecast_q50: 50th percentile (median)
# - forecast_q90: 90th percentile (upper bound)
```

**Visualization:**
```python
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(predictions['ds'], predictions['forecast'], label='Forecast')
plt.fill_between(
    predictions['ds'],
    predictions['forecast_q10'],
    predictions['forecast_q90'],
    alpha=0.3,
    label='80% Confidence Interval'
)
plt.legend()
plt.show()
```

---

## üêõ **Troubleshooting**

### **Issue: CUDA out of memory**
**Solution:** Reduce batch size
```yaml
batch_size: 16  # or even 8
```

### **Issue: Training very slow**
**Solution:** 
1. Check GPU is being used: `torch.cuda.is_available()`
2. Reduce epochs for testing: `epochs: 20`
3. Reduce context_length: `context_length: 60`

### **Issue: Poor accuracy**
**Solutions:**
1. Add more external features
2. Increase hidden_size: `hidden_size: 60`
3. Increase epochs: `epochs: 100`
4. Check data quality (missing values, outliers)

### **Issue: External features not working**
**Solution:** Ensure features are in your data:
```python
# Check columns
print(df.columns)

# Verify features exist
required_features = ['revenue', 'price']
missing = [f for f in required_features if f not in df.columns]
print(f"Missing features: {missing}")
```

---

## üìö **Advanced Usage**

### **Custom Loss Function**

```yaml
loss_function: "NegativeBinomial"  # For count data (sales)
# or "StudentT"  # For data with outliers
# or "Gaussian"  # For continuous data
```

### **Per-Product Training**

```python
# In data_formatting.py
dataset = formatter.create_dataset(df, per_item=True)
```

### **Custom Quantiles**

```python
predictions = predictor.predict(
    df,
    num_samples=100,
    quantiles=[0.05, 0.25, 0.5, 0.75, 0.95]
)
```

---

## üéì **Learning Resources**

- **GluonTS Documentation**: https://ts.gluon.ai/
- **DeepAR Paper**: https://arxiv.org/abs/1704.04110
- **PyTorch**: https://pytorch.org/
- **CUDA Setup**: https://pytorch.org/get-started/locally/

---

## ‚úÖ **Verification Checklist**

Before deploying:

- [ ] GPU detected and used (check logs)
- [ ] External features loaded correctly
- [ ] Training completes without errors
- [ ] Validation MAPE < 15%
- [ ] Predictions generated successfully
- [ ] Confidence intervals look reasonable
- [ ] Model saved with versioning

---

## üéâ **You're Ready!**

Your DeepAR implementation is **production-ready** with:
- ‚úÖ Full GluonTS integration
- ‚úÖ GPU acceleration
- ‚úÖ Multi-feature support
- ‚úÖ Probabilistic forecasting
- ‚úÖ Model versioning

**Start training and see the power of deep learning for forecasting!** üöÄ

---

**Questions?** Check the main `README_MULTI_MODEL.md` or review the code documentation.
